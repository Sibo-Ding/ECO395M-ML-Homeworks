---
title: "ECO395M DM&SL Exercise 2"
author: "Sibo Ding"
date: "Spring 2024"
output: md_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)

library(dplyr)
library(ggplot2)
library(caret)
library(pROC)
library(glmnet)  # Ridge and Lasso
```

## Saratoga house prices
```{r}
# Load data
library(mosaic)
data(SaratogaHouses)
unloadNamespace("mosaic")

# Identify numerical variables
numerical_vars <- sapply(SaratogaHouses, is.numeric)
# Standardize numerical variables
SaratogaStd <- SaratogaHouses
SaratogaStd[numerical_vars] <- scale(SaratogaHouses[numerical_vars])

# 10-fold cross validation
ctrl <- trainControl(method = "cv", number = 10)
```

I use linear regression and KNN regression models to predict the house price in Saratoga. I use 10-fold cross validation and out-of-sample RMSE to measure the model performance. I standardize variables to improve model performance.  

Linear regression results:
```{r}
# Linear
set.seed(12)
train(price ~ ., 
      data = SaratogaStd, method = "lm", trControl = ctrl)
```

KNN regression results:
```{r}
# KNN
set.seed(12)
train(price ~ . - fireplaces - fuel,
      data = SaratogaStd, method = "knn", trControl = ctrl)
```

The linear regression model has a better prediction performance, with a lower RMSE.

## Classification and retrospective sampling
```{r}
loan <- read.csv("german_credit.csv")
```

Bar plot of default probability by credit history:  
```{r}
loan |>
  group_by(history) |> summarize(default_prob = mean(Default)) |>
  ggplot(aes(history, default_prob)) +
  geom_col() + 
  labs(x = "Credit History", y = "Default Probability")
```

Logistic regression results:  
```{r}
# Logistic regression
loan_glm <- glm(Default ~ duration + amount + installment + age + history + purpose + foreign, family = "binomial", data = loan)
summary(loan_glm)
```

In both the bar plot (or the data set) and the logistic regression, compared to `historygood`, `historypoor` decreases the default probability, and `historyterrible` further decreases the default probability.  

This relationship is counter-intuitive, probably resulting from the inappropriate sampling process. To improve the sampling scheme, the bank can use undersampling, where it randomly remove loans that had not defaulted so that the class distribution becomes more balanced.

## Children and hotel reservations
```{r}
hotels_dev <- read.csv("hotels_dev.csv")
hotels_val <- read.csv("hotels_val.csv")

# Train-test split
set.seed(123)
index <- createDataPartition(hotels_dev$children,
                             p = 0.8, list = FALSE)
train <- hotels_dev[index, ]
test <- hotels_dev[-index, ]
```

### Model building
Baseline model 1. I choose threshold = 0.1 mainly considering a balance between true positive rate (sensitivity) and false positive rate (1 - specificity).
```{r}
# Fit logistic regression model
hotels_glm_1 <- glm(children ~ market_segment + adults + customer_type + is_repeated_guest,
                    family = "binomial", data = train)
# Predict probability
hotels_prob_1 <- predict(hotels_glm_1, test, type = "response")
# Determine 1 or 0 based on a threshold
hotels_pred_1 <- as.numeric(hotels_prob_1 > 0.1)
# Confusion matrix
confusionMatrix(factor(hotels_pred_1), factor(test$children))
```

Baseline model 2 at threshold = 0.1:
```{r}
hotels_glm_2 <- glm(children ~ . - arrival_date,
                    family = "binomial", data = train)
hotels_prob_2 <- predict(hotels_glm_2, test, type = "response")
hotels_pred_2 <- as.numeric(hotels_prob_2 > 0.1)
confusionMatrix(factor(hotels_pred_2), factor(test$children))
```

Best linear model at threshold = 0.1:
```{r}
hotels_glm_3 <- glm(children ~ . - arrival_date + hotel*adults + stays_in_week_nights*adults + is_repeated_guest*market_segment + is_repeated_guest*reserved_room_type,
                    family = "binomial", data = train)
hotels_prob_3 <- predict(hotels_glm_3, test, type = "response")
hotels_pred_3 <- as.numeric(hotels_prob_3 > 0.1)
confusionMatrix(factor(hotels_pred_3), factor(test$children))
```

### Model validation: step 1
ROC curve for the best model:  
```{r}
hotels_prob_val <- predict(hotels_glm_3, hotels_val, type = "response")
# ROC curve
plot(roc(hotels_val$children ~ hotels_prob_val))
```

### Model validation: step 2
I split the validation data set into 20 folds, where each fold has about 250 bookings. In each fold, I calculate the expected number of bookings with children versus the actual number of bookings with children.  
```{r}
# Create a shuffled column "fold_id"
set.seed(424)
hotels_val <- hotels_val |> mutate(fold_id =
  rep(1:20, length = nrow(hotels_val)) |> sample())

# Create an empty data frame
pred_actual <- data.frame()

# For each fold
for (fold in 1:20){
  # Create a temp data frame saving i-th fold
  temp <- hotels_val |> filter(fold_id == fold)
  # Sum predicted probabilities
  expected_children <- sum(
    predict(hotels_glm_3, temp, type = "response"))
  # Sum actual children
  actual_children <- sum(temp$children)
  # Add to existing data frame
  pred_actual <- pred_actual |>
    rbind(data.frame(fold, expected_children, actual_children))
}

pred_actual

pred_actual |> ggplot(aes(x = fold)) +
  geom_point(aes(y = expected_children, col = "Expected")) +
  geom_point(aes(y = actual_children, col = "Actual")) +
  labs(x = "Fold", y = "Number of children", col = "")
```

## Mushroom classification
The y variable is a dummy, where it equals to 1 if a mushroom is poisonous and 0 otherwise. I exclude `veil.type` from x variables as it has no variation.  
```{r}
mush <- read.csv("mushrooms.csv")
# Delete column "veil.type" as it has no variation
mush <- mush |> select(-veil.type)
# One-hot encoding
mush <- model.matrix(~ . - 1, data = mush)

x <- mush[, 3:ncol(mush)]
y <- mush[, 2]  # Poisonous

# Train-test split
set.seed(42)
train <- sample(1:nrow(mush), 0.8 * nrow(mush))
test <- (-train)
```

I use 10-fold cross validation to fit a lasso model and find an optimal lambda. The optimal lambda is:  
```{r}
# Fit a lasso using cross validation
set.seed(123)
lasso_cv <- cv.glmnet(x[train, ], y[train],
                      family = "binomial", alpha = 1, nfolds = 10)
# Find the optimal lambda
best_lambda <- lasso_cv$lambda.min
best_lambda
```

I use the optimal lambda to predict the out-of-sample probability that a mushroom is poisonous. ROC curve:  
```{r}
# Probability
lasso_prob <- predict(lasso_cv, s = best_lambda, newx = x[test, ],
                      type = "response")
# ROC
plot(roc(y[test] ~ lasso_prob))
```

I choose the threshold = 0.5. The model perfectly predicts poisonous mushrooms, with true positive rate (sensitivity) = 1 and false positive rate (1 - specificity) = 0.  
```{r}
lasso_pred <- as.numeric(lasso_prob > 0.5)
confusionMatrix(factor(lasso_pred), factor(y[test]))
```

To investigate this case, I plot the predicted probability versus whether a mushroom is poisonous (= 1 if poisonous). It can be seen the predicted probabilities cluster for two classes.  
```{r}
data.frame(lasso_prob, y[test]) |>
  ggplot(aes(y.test., s1)) +
  geom_point() +
  xlab("Poisonous or not") +
  ylab("Predicted probability")
```
