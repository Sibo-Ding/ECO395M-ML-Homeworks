---
title: "ECO395M DM&SL Exercise 2"
author: "Sibo Ding"
date: "Spring 2024"
output: md_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)

library(dplyr)
library(ggplot2)
library(caret)
library(pROC)
library(glmnet)  # Ridge and Lasso
```

## Saratoga house prices
```{r}
# Load data
library(mosaic)
data(SaratogaHouses)
unloadNamespace("mosaic")

# Identify numerical variables
numerical_vars <- sapply(SaratogaHouses, is.numeric)
# Standardize numerical variables
SaratogaStd <- SaratogaHouses
SaratogaStd[numerical_vars] <- scale(SaratogaHouses[numerical_vars])

# 10-fold cross validation
ctrl <- trainControl(method = "cv", number = 10)
```

I use two models and several features to predict the house price in Saratoga: linear regression and KNN regression. I use 10-fold cross validation and out-of-sample RMSE to measure the model performance. I standardize variables to improve model performance.  

Below is the results of linear regression:
```{r}
# Linear
set.seed(12)
train(price ~ ., 
      data = SaratogaStd, method = "lm", trControl = ctrl)
```

Below is the results of KNN regression:
```{r}
# KNN
set.seed(12)
train(price ~ . - fireplaces - fuel,
      data = SaratogaStd, method = "knn", trControl = ctrl)
```

The linear regression model has better prediction performance, with a lower RMSE.

## Classification and retrospective sampling
```{r}
loan <- read.csv("german_credit.csv")
```

Bar plot of default probability by credit history:  
```{r}
loan |>
  group_by(history) |> summarize(default_prob = mean(Default)) |>
  ggplot(aes(history, default_prob)) +
  geom_col() + 
  labs(x = "Credit History", y = "Default Probability")
```

Logistic regression results:
```{r}
# Logistic regression
loan_glm <- glm(Default ~ duration + amount + installment + age + history + purpose + foreign, family = "binomial", data = loan)
summary(loan_glm)
```
In the `history` variable: compared to `good` category, `poor` category decreases the default probability, and `terrible` category decreases the default probability even more. This is reasonable as low credit level means low payback ability, thus more likely to default.  

The sampling process (*"It then attempted to match each default with similar sets of loans that had not defaulted"*) is not appropriate for predicting defaults. Features used in prediction are similar between defaulted and not defaulted cases. Thus, the outcome variable `Default` has high variance and low robustness.

# would you recommend any changes to the bank's sampling scheme?







## Children and hotel reservations
```{r}
hotels_dev <- read.csv("hotels_dev.csv")
hotels_val <- read.csv("hotels_val.csv")
```

### Model building
```{r}
# Train-test split
set.seed(123)
index <- createDataPartition(hotels_dev$children,
                             p = 0.8, list = FALSE)
train <- hotels_dev[index, ]
test <- hotels_dev[-index, ]
```

Baseline model 1. I choose the threshold = 0.1 mainly considering a balance between true positive rate (sensitivity) and false positive rate (1 - specificity).
```{r}
# Fit logistic regression model
hotels_glm_1 <- glm(children ~ market_segment + adults + customer_type + is_repeated_guest,
                    family = "binomial", data = train)
# Predict probability
hotels_prob_1 <- predict(hotels_glm_1, test, type = "response")
# Determine 1 or 0 based on a threshold
hotels_pred_1 <- as.numeric(hotels_prob_1 > 0.1)
# Confusion matrix
confusionMatrix(factor(hotels_pred_1), factor(test$children))
```

Baseline model 2 at threshold = 0.1:
```{r}
hotels_glm_2 <- glm(children ~ . - arrival_date,
                    family = "binomial", data = train)
hotels_prob_2 <- predict(hotels_glm_2, test, type = "response")
hotels_pred_2 <- as.numeric(hotels_prob_2 > 0.1)
confusionMatrix(factor(hotels_pred_2), factor(test$children))
```




# the best linear model you can build, including any engineered features that you can think of that improve the performance (interactions, features derived from time stamps, etc).






Best linear model at threshold = 0.1:
```{r}
hotels_glm_3 <- glm(children ~ . - arrival_date,
                    family = "binomial", data = train)
hotels_prob_3 <- predict(hotels_glm_3, test, type = "response")
hotels_pred_3 <- as.numeric(hotels_prob_3 > 0.1)
confusionMatrix(factor(hotels_pred_3), factor(test$children))
```

### Model validation: step 1
ROC curve for the best model:  
```{r}
hotels_prob_val <- predict(hotels_glm_3, hotels_val, type = "response")
# ROC curve
plot(roc(hotels_val$children ~ hotels_prob_val))
```

### Model validation: step 2
I split the validation data set into 20 folds, where each fold has about 250 bookings. In each fold, I calculate the expected number of bookings with children versus the actual number of bookings with children.  
```{r}
# Create a shuffled column "fold_id"
set.seed(424)
hotels_val <- hotels_val |> mutate(fold_id =
  rep(1:20, length = nrow(hotels_val)) |> sample())

# Create an empty data frame
pred_actual <- data.frame()

# For each fold
for (fold in 1:20){
  # Create a temp data frame saving i-th fold
  temp <- hotels_val |> filter(fold_id == fold)
  # Sum predicted probabilities
  expected_children <- sum(
    predict(hotels_glm_3, temp, type = "response"))
  # Sum actual children
  actual_children <- sum(temp$children)
  # Add to existing data frame
  pred_actual <- pred_actual |>
    rbind(data.frame(fold, expected_children, actual_children))
}

pred_actual

pred_actual |> ggplot(aes(x = fold)) +
  geom_point(aes(y = expected_children, col = "Expected")) +
  geom_point(aes(y = actual_children, col = "Actual")) +
  labs(x = "Fold", y = "Number of children", col = "")
```

## Mushroom classification
The y variable is a dummy, where it equals 1 if a mushroom is poisonous and 0 otherwise. I exclude `veil.type` from x variables as it has no variation.  
```{r}
mush <- read.csv("mushrooms.csv")
# Delete column "veil.type" as it has no variation
mush <- mush |> select(-veil.type)
# One-hot encoding
mush <- model.matrix(~ . - 1, data = mush)

x <- mush[, 3:ncol(mush)]
y <- mush[, 2]  # Poisonous

# Train-test split
set.seed(42)
train <- sample(1:nrow(mush), 0.8 * nrow(mush))
test <- (-train)
```

I fit a lasso model, and use a 10-fold cross validation to choose an optimal lambda. The optimal lambda is:  
```{r}
# Fit a lasso model
lasso_mod <- glmnet(x[train, ], y[train], alpha = 1)
# Choosing an optimal lambda using cross validation
set.seed(123)
lasso_cv <- cv.glmnet(x[train, ], y[train], alpha = 1, nfolds = 10)
best_lambda <- lasso_cv$lambda.min
best_lambda
```

I use this optimal lambda to predict the out-of-sample probability that a mushroom is poisonous. ROC curve:  
```{r}
lasso_pred <- predict(lasso_mod, s = best_lambda, newx = x[test, ])
# ROC
plot(roc(y[test] ~ lasso_pred))
```







# Based on this ROC curve, recommend a probability threshold for declaring a mushroom poisonous. How well does your model perform at this threshold, as measured by false positive rate and true positive rate?













