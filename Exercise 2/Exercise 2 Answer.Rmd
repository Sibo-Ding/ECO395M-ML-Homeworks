---
title: "ECO395M DM&SL Exercise 2"
author: "Sibo Ding"
date: "Spring 2024"
output: md_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)

library(dplyr)
library(ggplot2)
library(caret)
```

## Saratoga house prices
```{r}
library(mosaic)
data(SaratogaHouses)
unloadNamespace("mosaic")

# 10-fold cross validation
ctrl <- trainControl(method = "cv", number = 10)

# Identify numerical variables
numerical_vars <- sapply(SaratogaHouses, is.numeric)
# Standardize numerical variables
SaratogaStd <- SaratogaHouses
SaratogaStd[numerical_vars] <- scale(SaratogaHouses[numerical_vars])
```

I use two models and several features to predict the house price in Saratoga: linear regression and KNN regression. I use 10-fold cross validation and out-of-sample RMSE to measure the model performance. I standardize variables to improve model performance.  

Below is the results of linear regression:
```{r}
# Linear
train(price ~ ., 
      data = SaratogaStd, method = "lm", trControl = ctrl)
```

Below is the results of KNN regression:
```{r}
# KNN
train(price ~ . - fireplaces - fuel,
      data = SaratogaStd, method = "knn", trControl = ctrl)
```

The linear regression model has better prediction performance, with a lower RMSE.

## Classification and retrospective sampling
```{r}
loan <- read.csv("german_credit.csv")
```

Bar plot of default probability by credit history:
```{r}
loan |>
  group_by(history) |> summarize(default_prob = mean(Default)) |>
  ggplot(aes(history, default_prob)) +
  geom_col() + 
  labs(x = "Credit History", y = "Default Probability")
```

Logistic regression results:
```{r}
# Logistic regression
loan_glm <- glm(Default ~ duration + amount + installment + age + history + purpose + foreign, family = binomial, data = loan)
summary(loan_glm)
```
In the `history` variable: compared to `good` category, `poor` category decreases the default probability, and `terrible` category decreases the default probability even more. This is reasonable as low credit level means low payback ability, thus more likely to default.  

The sampling process (*It then attempted to match each default with similar sets of loans that had not defaulted*) is not appropriate for predicting defaults. Features used in prediction are similar between defaulted and not defaulted cases. Thus, the outcome variable `Default` has high variance and low robustness.

# would you recommend any changes to the bank's sampling scheme?







## Children and hotel reservations
```{r}
hotels_dev <- read.csv("hotels_dev.csv")
hotels_val <- read.csv("hotels_val.csv")
```







### Model building







### Model validation: step 1






### Model validation: step 2







## Mushroom classification
```{r}
mush <- read.csv("mushrooms.csv")
```





